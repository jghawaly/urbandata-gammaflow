{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARAD (Autoencoder Reconstruction Anomaly Detection)\n",
        "\n",
        "This notebook demonstrates the ARAD algorithm for identifying radioactive sources in gamma-ray time series data using a trained autoencoder.\n",
        "\n",
        "## Algorithm Overview\n",
        "\n",
        "The ARAD detector:\n",
        "1. **Learns background patterns** using a convolutional autoencoder on source-absent training data\n",
        "2. **Computes reconstruction error** using Chi Squared between input and reconstruction\n",
        "3. **Detects anomalies** when reconstruction error exceeds threshold\n",
        "4. **Aggregates alarms** that are close in time\n",
        "\n",
        "## Key Features\n",
        "- **Deep learning**: Uses convolutional autoencoder to capture complex spectral patterns\n",
        "- **Chi2 metric**: More robust than MSE for spectral comparison\n",
        "- **Unsupervised**: Only needs background data for training\n",
        "- **Interpretable**: Reconstruction error + saliency maps show what's anomalous\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Using the TopCoder Urban Data Challenge dataset (mobile NaI detector).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys\n",
        "sys.path.insert(0, '../../gammaflow')\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# GammaFlow imports\n",
        "from gammaflow import Spectrum, SpectralTimeSeries, ListMode\n",
        "from gammaflow.core.spectra import Spectra\n",
        "from gammaflow.visualization import plot_count_rate_time_series\n",
        "\n",
        "# Detection algorithm\n",
        "from src.detectors import ARADDetector\n",
        "\n",
        "# Configure plotting\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✅ ARAD Detection - Ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data Helper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_listmode_run(run_id, data_dir='../topcoder', dataset='training'):\n",
        "    \"\"\"Load a run and return ListMode object + metadata.\"\"\"\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    # Load listmode data\n",
        "    run_file = data_path / dataset / f\"{run_id}.csv\"\n",
        "    data = pd.read_csv(run_file, header=None, names=['time_delta_us', 'energy_keV'])\n",
        "    \n",
        "    # Convert to seconds\n",
        "    time_deltas = data['time_delta_us'].values * 1e-6\n",
        "    energies = data['energy_keV'].values\n",
        "    \n",
        "    # Load metadata\n",
        "    answer_key_file = data_path / 'scorer' / f'answerKey_{dataset}.csv'\n",
        "    answer_key = pd.read_csv(answer_key_file)\n",
        "    metadata = answer_key[answer_key['RunID'] == run_id].iloc[0].to_dict()\n",
        "    \n",
        "    # Map SourceID to source name\n",
        "    source_map = {\n",
        "        0: 'Background',\n",
        "        1: 'HEU',\n",
        "        2: 'WGPu',\n",
        "        3: 'I-131',\n",
        "        4: 'Co-60',\n",
        "        5: 'Tc-99m',\n",
        "        6: 'Tc-99m + HEU'\n",
        "    }\n",
        "    metadata['SourceName'] = source_map.get(metadata['SourceID'], f\"Unknown({metadata['SourceID']})\")\n",
        "    \n",
        "    # Create ListMode\n",
        "    listmode = ListMode(time_deltas, energies)\n",
        "    \n",
        "    return listmode, metadata\n",
        "\n",
        "print(\"✅ Load function ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Trained ARAD Model\n",
        "\n",
        "We'll load the ARAD model that was trained on background data using the `train_arad.py` script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained ARAD detector\n",
        "model_path = '../models/arad_background.pt'\n",
        "\n",
        "print(f\"Loading trained ARAD model from {model_path}...\")\n",
        "\n",
        "detector = ARADDetector(\n",
        "    latent_dim=8,\n",
        "    dropout=0.2,\n",
        "    aggregation_gap=2.0,  # Merge alarms < 2 seconds apart\n",
        "    verbose=True,\n",
        "    loss_type='chi2'\n",
        ")\n",
        "\n",
        "detector.load(model_path)\n",
        "\n",
        "print(f\"\\n✅ Model loaded successfully!\")\n",
        "print(f\"   Model config:\")\n",
        "print(f\"     - Latent dimension: {detector.latent_dim}\")\n",
        "print(f\"     - Number of bins: {detector.n_bins_}\")\n",
        "print(f\"     - Device: {detector.device}\")\n",
        "print(f\"     - Current threshold: {detector.threshold if detector.threshold is not None else 'Not set'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Threshold Based on False Alarm Rate\n",
        "\n",
        "We'll calibrate the threshold using the **alarms per hour** metric, which is the standard for operational radiation detection systems. ANSI N42.48 typically requires **< 1 alarm/hour** for nuisance alarm rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load background time series for threshold calibration\n",
        "# NOTE: Using just the first background run (same approach as SAD detector)\n",
        "# This is faster and provides a fair comparison between algorithms.\n",
        "#\n",
        "# ⚠️  FOR REAL-WORLD/PRODUCTION USE: You should calibrate on MULTIPLE background\n",
        "#     runs (e.g., 20+) to get robust statistics and account for environmental\n",
        "#     variations, detector drift, and different background conditions. Using a\n",
        "#     single run is acceptable for testing and algorithm comparison, but not\n",
        "#     for operational deployment.\n",
        "print(\"Loading background time series for threshold calibration...\")\n",
        "\n",
        "data_path = Path('../topcoder')\n",
        "answer_key = pd.read_csv(data_path / 'scorer' / 'answerKey_training.csv')\n",
        "background_run_ids = answer_key[answer_key['SourceID'] == 0]['RunID'].values\n",
        "\n",
        "# Load just the first background run (matches SAD's approach)\n",
        "print(f\"Using first background run (ID: {background_run_ids[0]}) for calibration...\")\n",
        "listmode, _ = load_listmode_run(background_run_ids[0])\n",
        "calibration_data = SpectralTimeSeries.from_list_mode(\n",
        "    listmode,\n",
        "    integration_time=3.0,  # 1-second integration\n",
        "    stride_time=1.0,\n",
        "    energy_bins=128,\n",
        "    energy_range=(20, 2900)\n",
        ")\n",
        "\n",
        "print(f\"\\nCalibration dataset: {calibration_data.n_spectra} spectra\")\n",
        "total_time_hours = np.sum(calibration_data.real_times) / 3600.0\n",
        "print(f\"  Total observation time: {total_time_hours:.2f} hours\")\n",
        "\n",
        "# Set threshold\n",
        "alarms_per_hour = 0.5  # Conservative target (ANSI compliant)\n",
        "\n",
        "print(f\"\\nSetting threshold for {alarms_per_hour} alarms per hour...\")\n",
        "threshold = detector.set_threshold_by_far(calibration_data, alarms_per_hour=alarms_per_hour, max_iterations=100)\n",
        "\n",
        "print(f\"\\n✅ Threshold set: {threshold:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Run with Source\n",
        "\n",
        "Now let's test the detector on a run with a radioactive source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load I-131 run with strongest source\n",
        "i131_runs = answer_key[answer_key['SourceID'] == 3].copy()\n",
        "i131_runs = i131_runs.sort_values('Speed/Offset', ascending=False)\n",
        "\n",
        "# Pick the strongest run\n",
        "test_run_id = i131_runs.iloc[0]['RunID']\n",
        "speed_offset = i131_runs.iloc[0]['Speed/Offset']\n",
        "\n",
        "print(f\"Loading I-131 test run {test_run_id}...\")\n",
        "print(f\"  Speed/Offset: {speed_offset:.2f} (stronger is better)\")\n",
        "listmode, metadata = load_listmode_run(int(test_run_id))\n",
        "\n",
        "print(f\"\\nRun Metadata:\")\n",
        "print(f\"  Source: {metadata['SourceName']}\")\n",
        "print(f\"  Source Time: {metadata['SourceTime']:.1f} seconds\")\n",
        "print(f\"  Speed/Offset: {metadata['Speed/Offset']:.2f}\")\n",
        "print(f\"\\n{listmode}\")\n",
        "\n",
        "# Convert to time series with 1-second integration\n",
        "print(\"\\nConverting to SpectralTimeSeries...\")\n",
        "test_time_series = SpectralTimeSeries.from_list_mode(\n",
        "    listmode,\n",
        "    integration_time=3.0,\n",
        "    stride_time=1.0,\n",
        "    energy_bins=128,\n",
        "    energy_range=(20, 2900)\n",
        ")\n",
        "\n",
        "print(f\"\\nCreated: {test_time_series}\")\n",
        "print(f\"  Number of spectra: {test_time_series.n_spectra}\")\n",
        "print(f\"  Time coverage: {test_time_series.timestamps[0]:.1f} to {test_time_series.timestamps[-1]:.1f} s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ARAD Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Running ARAD Detection\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Latent dimension: {detector.latent_dim}\")\n",
        "print(f\"  Threshold: {detector.threshold:.4f}\")\n",
        "print(f\"  Device: {detector.device}\")\n",
        "print()\n",
        "\n",
        "# Process time series\n",
        "arad_scores, alarms = detector.detect(test_time_series)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Detection Results\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Number of alarms: {len(alarms)}\")\n",
        "\n",
        "if len(alarms) > 0:\n",
        "    total_alarm_time = sum(alarm['end_time'] - alarm['start_time'] for alarm in alarms)\n",
        "    mean_duration = total_alarm_time / len(alarms)\n",
        "    max_score = max(alarm['peak_score'] for alarm in alarms)\n",
        "    \n",
        "    print(f\"Total alarm time: {total_alarm_time:.2f} seconds\")\n",
        "    print(f\"Mean alarm duration: {mean_duration:.2f} seconds\")\n",
        "    print(f\"Peak ARAD score: {max_score:.4f}\")\n",
        "    \n",
        "    print(f\"\\nAlarm Events:\")\n",
        "    true_source_time = metadata['SourceTime']\n",
        "    for i, alarm in enumerate(alarms, 1):\n",
        "        duration = alarm['end_time'] - alarm['start_time']\n",
        "        print(f\"  {i}. Alarm: t=[{alarm['start_time']:.1f}, {alarm['end_time']:.1f}]s, \"\n",
        "              f\"peak={alarm['peak_score']:.4f} at t={alarm['peak_time']:.1f}s, duration={duration:.1f}s\")\n",
        "        \n",
        "        # Compare to ground truth\n",
        "        if alarm['start_time'] <= true_source_time <= alarm['end_time']:\n",
        "            print(f\"      ✅ Captured true source (t={true_source_time:.1f}s)\")\n",
        "        else:\n",
        "            time_diff = min(abs(alarm['start_time'] - true_source_time),\n",
        "                          abs(alarm['end_time'] - true_source_time))\n",
        "            print(f\"      ⚠️  Offset from true source: {time_diff:.1f}s\")\n",
        "else:\n",
        "    print(\"No alarms detected!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ARAD scores with alarm overlay\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Get times and count rates\n",
        "times = test_time_series.timestamps\n",
        "count_rates = np.array([\n",
        "    float(test_time_series[i].counts.sum()) / float(\n",
        "        test_time_series[i].live_time \n",
        "        if (test_time_series[i].live_time is not None and not np.isnan(test_time_series[i].live_time))\n",
        "        else test_time_series[i].real_time\n",
        "    )\n",
        "    for i in range(test_time_series.n_spectra)\n",
        "])\n",
        "\n",
        "# Plot 1: Count rate\n",
        "ax1.step(times, count_rates, where='post', color='black', linewidth=1.5, label='Count rate')\n",
        "ax1.set_ylabel(r'Count Rate (s$^{-1}$)', fontsize=12)\n",
        "ax1.set_title(f'ARAD Detection Results - Run {test_run_id} ({metadata[\"SourceName\"]})', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight alarms\n",
        "for alarm in alarms:\n",
        "    ax1.axvspan(alarm['start_time'], alarm['end_time'], alpha=0.3, color='red', label='Alarm')\n",
        "\n",
        "# Mark true source time\n",
        "ax1.axvline(metadata['SourceTime'], color='green', linestyle='--', linewidth=2, \n",
        "            label=f\"True source (t={metadata['SourceTime']:.1f}s)\")\n",
        "\n",
        "# Remove duplicate labels\n",
        "handles, labels = ax1.get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "ax1.legend(by_label.values(), by_label.keys(), fontsize=11)\n",
        "\n",
        "# Plot 2: ARAD scores\n",
        "ax2.step(times, arad_scores, where='post', color='steelblue', linewidth=1.5, label='ARAD Score')\n",
        "ax2.axhline(detector.threshold, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Threshold ({detector.threshold:.4f})')\n",
        "ax2.set_xlabel('Time (s)', fontsize=12)\n",
        "ax2.set_ylabel('ARAD Score (CHI 2)', fontsize=12)\n",
        "ax2.set_title('ARAD Score Time Series', fontsize=13, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight alarms\n",
        "for alarm in alarms:\n",
        "    ax2.axvspan(alarm['start_time'], alarm['end_time'], alpha=0.3, color='red')\n",
        "\n",
        "# Mark true source time\n",
        "ax2.axvline(metadata['SourceTime'], color='green', linestyle='--', linewidth=2)\n",
        "\n",
        "ax2.legend(fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Detection visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explainability: Saliency Maps\n",
        "\n",
        "The ARAD detector includes **explainable AI** capabilities through saliency maps. These show which energy bins contribute most to the anomaly score, helping us understand *why* the model detected an anomaly.\n",
        "\n",
        "We'll visualize saliency for the spectrum at the peak detection time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the spectrum at peak alarm time\n",
        "if len(alarms) > 0:\n",
        "    # Get the peak detection time (when ARAD score was highest)\n",
        "    peak_alarm = max(alarms, key=lambda a: a['peak_score'])\n",
        "    peak_time = peak_alarm['peak_time']\n",
        "    \n",
        "    # Find the spectrum closest to peak time\n",
        "    time_diffs = np.abs(times - peak_time)\n",
        "    peak_idx = np.argmin(time_diffs)\n",
        "    peak_spectrum = test_time_series[peak_idx]\n",
        "    \n",
        "    print(f\"Analyzing spectrum at peak detection:\")\n",
        "    print(f\"  Time: {times[peak_idx]:.1f}s (true source at {metadata['SourceTime']:.1f}s)\")\n",
        "    print(f\"  ARAD score: {arad_scores[peak_idx]:.4f}\")\n",
        "    print(f\"  Total counts: {peak_spectrum.counts.sum():.0f}\")\n",
        "    print()\n",
        "    \n",
        "    # Visualize saliency using both methods\n",
        "    print(\"Computing saliency maps...\")\n",
        "    \n",
        "    # Method 1: Gradient-based saliency (fast)\n",
        "    fig1, axes1 = detector.plot_saliency(\n",
        "        peak_spectrum,\n",
        "        method='gradient',\n",
        "        figsize=(14, 10),\n",
        "        show_reconstruction=True\n",
        "    )\n",
        "    axes1[0].set_title(\n",
        "        f'Gradient-Based Saliency at t={times[peak_idx]:.1f}s (Score={arad_scores[peak_idx]:.4f})',\n",
        "        fontsize=13,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "    plt.show()\n",
        "    \n",
        "    # Method 2: Integrated gradients (more robust, slower)\n",
        "    print(\"\\nComputing integrated gradients (this may take a moment)...\")\n",
        "    fig2, axes2 = detector.plot_saliency(\n",
        "        peak_spectrum,\n",
        "        method='integrated',\n",
        "        figsize=(14, 10),\n",
        "        show_reconstruction=True\n",
        "    )\n",
        "    axes2[0].set_title(\n",
        "        f'Integrated Gradients Saliency at t={times[peak_idx]:.1f}s (Score={arad_scores[peak_idx]:.4f})',\n",
        "        fontsize=13,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "    plt.show()\n",
        "    \n",
        "    # Print interpretation\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Interpretation\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"The RED highlighting shows energy regions that contribute most to the\")\n",
        "    print(\"anomaly score. These are the spectral features that the autoencoder\")\n",
        "    print(\"struggles to reconstruct, indicating source presence.\")\n",
        "    print()\n",
        "    print(\"For I-131 detection, look for:\")\n",
        "    print(\"  • 364 keV photopeak\")\n",
        "    print(\"  • 637 keV photopeak\") \n",
        "    print(\"  • Other characteristic gamma lines\")\n",
        "    print()\n",
        "    print(\"The saliency map helps verify the model is focusing on physically\")\n",
        "    print(\"meaningful features rather than noise or artifacts.\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠️  No alarms detected - cannot compute saliency maps.\")\n",
        "    print(\"    Try lowering the threshold or using a different test run.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Compare Background vs Source Saliency\n",
        "\n",
        "Let's compare the saliency maps for a background spectrum (before source) and the source spectrum to see the difference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare saliency for background vs source spectra\n",
        "if len(alarms) > 0:\n",
        "    # Get background spectrum (before source appears)\n",
        "    source_time = metadata['SourceTime']\n",
        "    bg_times = times[times < (source_time - 5)]  # At least 5s before source\n",
        "    \n",
        "    if len(bg_times) > 0:\n",
        "        bg_idx = len(bg_times) // 2  # Pick middle of background period\n",
        "        bg_spectrum = test_time_series[bg_idx]\n",
        "        bg_score = arad_scores[bg_idx]\n",
        "        \n",
        "        # Get source spectrum (at peak)\n",
        "        peak_alarm = max(alarms, key=lambda a: a['peak_score'])\n",
        "        peak_time = peak_alarm['peak_time']\n",
        "        time_diffs = np.abs(times - peak_time)\n",
        "        source_idx = np.argmin(time_diffs)\n",
        "        source_spectrum = test_time_series[source_idx]\n",
        "        source_score = arad_scores[source_idx]\n",
        "        \n",
        "        print(f\"Comparing saliency maps:\")\n",
        "        print(f\"  Background: t={times[bg_idx]:.1f}s, score={bg_score:.4f}\")\n",
        "        print(f\"  Source:     t={times[source_idx]:.1f}s, score={source_score:.4f}\")\n",
        "        print()\n",
        "        \n",
        "        # Create side-by-side comparison\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        \n",
        "        # Get data for both spectra\n",
        "        bg_counts = bg_spectrum.counts\n",
        "        bg_time_val = bg_spectrum.live_time if (bg_spectrum.live_time is not None and not np.isnan(bg_spectrum.live_time)) else bg_spectrum.real_time\n",
        "        bg_rate = bg_counts / bg_time_val\n",
        "        \n",
        "        source_counts = source_spectrum.counts\n",
        "        source_time_val = source_spectrum.live_time if (source_spectrum.live_time is not None and not np.isnan(source_spectrum.live_time)) else source_spectrum.real_time\n",
        "        source_rate = source_counts / source_time_val\n",
        "        \n",
        "        energy_centers = bg_spectrum.energy_centers\n",
        "        \n",
        "        # Compute saliency\n",
        "        bg_saliency = detector.compute_saliency_map(bg_spectrum, method='gradient')\n",
        "        source_saliency = detector.compute_saliency_map(source_spectrum, method='gradient')\n",
        "        \n",
        "        # Normalize saliency for visualization\n",
        "        bg_saliency_norm = bg_saliency / (np.max(bg_saliency) + 1e-10)\n",
        "        source_saliency_norm = source_saliency / (np.max(source_saliency) + 1e-10)\n",
        "        \n",
        "        # Plot background spectrum with saliency\n",
        "        ax1 = axes[0, 0]\n",
        "        ax1.plot(energy_centers, bg_rate, 'k-', linewidth=2, label='Background Spectrum')\n",
        "        for i in range(len(energy_centers) - 1):\n",
        "            ax1.axvspan(energy_centers[i], energy_centers[i+1], \n",
        "                       alpha=0.3 * bg_saliency_norm[i], color='orange')\n",
        "        ax1.set_yscale('log')\n",
        "        ax1.set_ylabel('Count Rate (s$^{-1}$)', fontsize=11)\n",
        "        ax1.set_title(f'Background (t={times[bg_idx]:.1f}s, score={bg_score:.4f})', \n",
        "                     fontsize=12, fontweight='bold')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.legend()\n",
        "        \n",
        "        # Plot source spectrum with saliency\n",
        "        ax2 = axes[0, 1]\n",
        "        ax2.plot(energy_centers, source_rate, 'k-', linewidth=2, label='Source Spectrum')\n",
        "        for i in range(len(energy_centers) - 1):\n",
        "            ax2.axvspan(energy_centers[i], energy_centers[i+1], \n",
        "                       alpha=0.3 * source_saliency_norm[i], color='red')\n",
        "        ax2.set_yscale('log')\n",
        "        ax2.set_ylabel('Count Rate (s$^{-1}$)', fontsize=11)\n",
        "        ax2.set_title(f'Source Present (t={times[source_idx]:.1f}s, score={source_score:.4f})', \n",
        "                     fontsize=12, fontweight='bold')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.legend()\n",
        "        \n",
        "        # Plot saliency comparison\n",
        "        ax3 = axes[1, 0]\n",
        "        ax3.plot(energy_centers, bg_saliency, 'orange', linewidth=2, label='Background Saliency')\n",
        "        ax3.fill_between(energy_centers, 0, bg_saliency, alpha=0.3, color='orange')\n",
        "        ax3.set_xlabel('Energy (keV)', fontsize=11)\n",
        "        ax3.set_ylabel('Saliency (|∂Loss/∂Input|)', fontsize=11)\n",
        "        ax3.set_title('Background Saliency Distribution', fontsize=12, fontweight='bold')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.legend()\n",
        "        \n",
        "        ax4 = axes[1, 1]\n",
        "        ax4.plot(energy_centers, source_saliency, 'red', linewidth=2, label='Source Saliency')\n",
        "        ax4.fill_between(energy_centers, 0, source_saliency, alpha=0.3, color='red')\n",
        "        ax4.set_xlabel('Energy (keV)', fontsize=11)\n",
        "        ax4.set_ylabel('Saliency (|∂Loss/∂Input|)', fontsize=11)\n",
        "        ax4.set_title('Source Saliency Distribution', fontsize=12, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        ax4.legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Observations\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"• Background spectra show LOW, diffuse saliency (model reconstructs well)\")\n",
        "        print(\"• Source spectra show HIGH, localized saliency at characteristic energies\")\n",
        "        print(\"• The model has learned what 'normal' background looks like and flags\")\n",
        "        print(\"  deviations as anomalous\")\n",
        "        print()\n",
        "        print(\"This demonstrates that ARAD is not just detecting 'different' spectra,\")\n",
        "        print(\"but specifically identifying features that deviate from learned background.\")\n",
        "        \n",
        "    else:\n",
        "        print(\"⚠️  Not enough background data before source appearance\")\n",
        "else:\n",
        "    print(\"⚠️  No alarms detected - skipping comparison\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The ARAD detector successfully identified the source by learning background patterns and detecting when spectra deviate from the learned representation. The reconstruction error (CHI2) is higher for source-present spectra, enabling detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
