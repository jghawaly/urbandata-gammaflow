{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARAD (Autoencoder Reconstruction Anomaly Detection)\n",
        "\n",
        "This notebook demonstrates the ARAD algorithm for identifying radioactive sources in gamma-ray time series data using a trained autoencoder.\n",
        "\n",
        "## Algorithm Overview\n",
        "\n",
        "The ARAD detector:\n",
        "1. **Learns background patterns** using a convolutional autoencoder on source-absent training data\n",
        "2. **Computes reconstruction error** using Chi Squared between input and reconstruction\n",
        "3. **Detects anomalies** when reconstruction error exceeds threshold\n",
        "4. **Aggregates alarms** that are close in time\n",
        "\n",
        "## Key Features\n",
        "- **Deep learning**: Uses convolutional autoencoder to capture complex spectral patterns\n",
        "- **Chi2 metric**: More robust than MSE for spectral comparison\n",
        "- **Unsupervised**: Only needs background data for training\n",
        "- **Interpretable**: Reconstruction error + saliency maps show what's anomalous\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Using the TopCoder Urban Data Challenge dataset (mobile NaI detector).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys\n",
        "sys.path.insert(0, '../../gammaflow')\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# GammaFlow imports\n",
        "from gammaflow import Spectrum, SpectralTimeSeries, ListMode\n",
        "from gammaflow.core.spectra import Spectra\n",
        "from gammaflow.visualization import plot_count_rate_time_series\n",
        "\n",
        "# Detection algorithm\n",
        "from src.detectors import ARADDetector\n",
        "\n",
        "# Configure plotting\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✅ ARAD Detection - Ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data Helper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_listmode_run(run_id, data_dir='../topcoder', dataset='training'):\n",
        "    \"\"\"Load a run and return ListMode object + metadata.\"\"\"\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    # Load listmode data\n",
        "    run_file = data_path / dataset / f\"{run_id}.csv\"\n",
        "    data = pd.read_csv(run_file, header=None, names=['time_delta_us', 'energy_keV'])\n",
        "    \n",
        "    # Convert to seconds\n",
        "    time_deltas = data['time_delta_us'].values * 1e-6\n",
        "    energies = data['energy_keV'].values\n",
        "    \n",
        "    # Load metadata\n",
        "    answer_key_file = data_path / 'scorer' / f'answerKey_{dataset}.csv'\n",
        "    answer_key = pd.read_csv(answer_key_file)\n",
        "    metadata = answer_key[answer_key['RunID'] == run_id].iloc[0].to_dict()\n",
        "    \n",
        "    # Map SourceID to source name\n",
        "    source_map = {\n",
        "        0: 'Background',\n",
        "        1: 'HEU',\n",
        "        2: 'WGPu',\n",
        "        3: 'I-131',\n",
        "        4: 'Co-60',\n",
        "        5: 'Tc-99m',\n",
        "        6: 'Tc-99m + HEU'\n",
        "    }\n",
        "    metadata['SourceName'] = source_map.get(metadata['SourceID'], f\"Unknown({metadata['SourceID']})\")\n",
        "    \n",
        "    # Create ListMode\n",
        "    listmode = ListMode(time_deltas, energies)\n",
        "    \n",
        "    return listmode, metadata\n",
        "\n",
        "print(\"✅ Load function ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Trained ARAD Model\n",
        "\n",
        "We'll load the ARAD model that was trained on background data using the `train_arad.py` script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained ARAD detector\n",
        "model_path = '../models/arad_background.pt'\n",
        "\n",
        "print(f\"Loading trained ARAD model from {model_path}...\")\n",
        "\n",
        "detector = ARADDetector(\n",
        "    latent_dim=8,\n",
        "    dropout=0.2,\n",
        "    aggregation_gap=2.0,  # Merge alarms < 2 seconds apart\n",
        "    verbose=True,\n",
        "    loss_type='chi2'\n",
        ")\n",
        "\n",
        "detector.load(model_path)\n",
        "\n",
        "print(f\"\\n✅ Model loaded successfully!\")\n",
        "print(f\"   Model config:\")\n",
        "print(f\"     - Latent dimension: {detector.latent_dim}\")\n",
        "print(f\"     - Number of bins: {detector.n_bins_}\")\n",
        "print(f\"     - Device: {detector.device}\")\n",
        "print(f\"     - Current threshold: {detector.threshold if detector.threshold is not None else 'Not set'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Threshold Based on False Alarm Rate\n",
        "\n",
        "We'll calibrate the threshold using the **alarms per hour** metric, which is the standard for operational radiation detection systems. ANSI N42.48 typically requires **< 1 alarm/hour** for nuisance alarm rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load background time series for threshold calibration\n",
        "# NOTE: Using just the first background run (same approach as SAD detector)\n",
        "# This is faster and provides a fair comparison between algorithms.\n",
        "#\n",
        "# ⚠️  FOR REAL-WORLD/PRODUCTION USE: You should calibrate on MULTIPLE background\n",
        "#     runs (e.g., 20+) to get robust statistics and account for environmental\n",
        "#     variations, detector drift, and different background conditions. Using a\n",
        "#     single run is acceptable for testing and algorithm comparison, but not\n",
        "#     for operational deployment.\n",
        "print(\"Loading background time series for threshold calibration...\")\n",
        "\n",
        "data_path = Path('../topcoder')\n",
        "answer_key = pd.read_csv(data_path / 'scorer' / 'answerKey_training.csv')\n",
        "background_run_ids = answer_key[answer_key['SourceID'] == 0]['RunID'].values\n",
        "\n",
        "# Load just the first background run (matches SAD's approach)\n",
        "print(f\"Using first background run (ID: {background_run_ids[0]}) for calibration...\")\n",
        "listmode, _ = load_listmode_run(background_run_ids[0])\n",
        "calibration_data = SpectralTimeSeries.from_list_mode(\n",
        "    listmode,\n",
        "    integration_time=3.0,  # 1-second integration\n",
        "    stride_time=1.0,\n",
        "    energy_bins=128,\n",
        "    energy_range=(20, 2900)\n",
        ")\n",
        "\n",
        "print(f\"\\nCalibration dataset: {calibration_data.n_spectra} spectra\")\n",
        "total_time_hours = np.sum(calibration_data.real_times) / 3600.0\n",
        "print(f\"  Total observation time: {total_time_hours:.2f} hours\")\n",
        "\n",
        "# Set threshold\n",
        "alarms_per_hour = 0.5  # Conservative target (ANSI compliant)\n",
        "\n",
        "print(f\"\\nSetting threshold for {alarms_per_hour} alarms per hour...\")\n",
        "threshold = detector.set_threshold_by_far(calibration_data, alarms_per_hour=alarms_per_hour, max_iterations=100)\n",
        "\n",
        "print(f\"\\n✅ Threshold set: {threshold:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test on Run with Source\n",
        "\n",
        "Now let's test the detector on a run with a radioactive source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load I-131 run with strongest source\n",
        "i131_runs = answer_key[answer_key['SourceID'] == 3].copy()\n",
        "i131_runs = i131_runs.sort_values('Speed/Offset', ascending=False)\n",
        "\n",
        "# Pick the strongest run\n",
        "test_run_id = i131_runs.iloc[0]['RunID']\n",
        "speed_offset = i131_runs.iloc[0]['Speed/Offset']\n",
        "\n",
        "print(f\"Loading I-131 test run {test_run_id}...\")\n",
        "print(f\"  Speed/Offset: {speed_offset:.2f} (stronger is better)\")\n",
        "listmode, metadata = load_listmode_run(int(test_run_id))\n",
        "\n",
        "print(f\"\\nRun Metadata:\")\n",
        "print(f\"  Source: {metadata['SourceName']}\")\n",
        "print(f\"  Source Time: {metadata['SourceTime']:.1f} seconds\")\n",
        "print(f\"  Speed/Offset: {metadata['Speed/Offset']:.2f}\")\n",
        "print(f\"\\n{listmode}\")\n",
        "\n",
        "# Convert to time series with 1-second integration\n",
        "print(\"\\nConverting to SpectralTimeSeries...\")\n",
        "test_time_series = SpectralTimeSeries.from_list_mode(\n",
        "    listmode,\n",
        "    integration_time=3.0,\n",
        "    stride_time=1.0,\n",
        "    energy_bins=128,\n",
        "    energy_range=(20, 2900)\n",
        ")\n",
        "\n",
        "print(f\"\\nCreated: {test_time_series}\")\n",
        "print(f\"  Number of spectra: {test_time_series.n_spectra}\")\n",
        "print(f\"  Time coverage: {test_time_series.timestamps[0]:.1f} to {test_time_series.timestamps[-1]:.1f} s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ARAD Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Running ARAD Detection\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Latent dimension: {detector.latent_dim}\")\n",
        "print(f\"  Threshold: {detector.threshold:.4f}\")\n",
        "print(f\"  Device: {detector.device}\")\n",
        "print()\n",
        "\n",
        "# Process time series\n",
        "arad_scores, alarms = detector.detect(test_time_series)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Detection Results\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Number of alarms: {len(alarms)}\")\n",
        "\n",
        "if len(alarms) > 0:\n",
        "    total_alarm_time = sum(alarm['end_time'] - alarm['start_time'] for alarm in alarms)\n",
        "    mean_duration = total_alarm_time / len(alarms)\n",
        "    max_score = max(alarm['peak_score'] for alarm in alarms)\n",
        "    \n",
        "    print(f\"Total alarm time: {total_alarm_time:.2f} seconds\")\n",
        "    print(f\"Mean alarm duration: {mean_duration:.2f} seconds\")\n",
        "    print(f\"Peak ARAD score: {max_score:.4f}\")\n",
        "    \n",
        "    print(f\"\\nAlarm Events:\")\n",
        "    true_source_time = metadata['SourceTime']\n",
        "    for i, alarm in enumerate(alarms, 1):\n",
        "        duration = alarm['end_time'] - alarm['start_time']\n",
        "        print(f\"  {i}. Alarm: t=[{alarm['start_time']:.1f}, {alarm['end_time']:.1f}]s, \"\n",
        "              f\"peak={alarm['peak_score']:.4f} at t={alarm['peak_time']:.1f}s, duration={duration:.1f}s\")\n",
        "        \n",
        "        # Compare to ground truth\n",
        "        if alarm['start_time'] <= true_source_time <= alarm['end_time']:\n",
        "            print(f\"      ✅ Captured true source (t={true_source_time:.1f}s)\")\n",
        "        else:\n",
        "            time_diff = min(abs(alarm['start_time'] - true_source_time),\n",
        "                          abs(alarm['end_time'] - true_source_time))\n",
        "            print(f\"      ⚠️  Offset from true source: {time_diff:.1f}s\")\n",
        "else:\n",
        "    print(\"No alarms detected!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ARAD scores with alarm overlay\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Get times and count rates\n",
        "times = test_time_series.timestamps\n",
        "count_rates = np.array([\n",
        "    float(test_time_series[i].counts.sum()) / float(\n",
        "        test_time_series[i].live_time \n",
        "        if (test_time_series[i].live_time is not None and not np.isnan(test_time_series[i].live_time))\n",
        "        else test_time_series[i].real_time\n",
        "    )\n",
        "    for i in range(test_time_series.n_spectra)\n",
        "])\n",
        "\n",
        "# Plot 1: Count rate\n",
        "ax1.step(times, count_rates, where='post', color='black', linewidth=1.5, label='Count rate')\n",
        "ax1.set_ylabel(r'Count Rate (s$^{-1}$)', fontsize=12)\n",
        "ax1.set_title(f'ARAD Detection Results - Run {test_run_id} ({metadata[\"SourceName\"]})', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight alarms\n",
        "for alarm in alarms:\n",
        "    ax1.axvspan(alarm['start_time'], alarm['end_time'], alpha=0.3, color='red', label='Alarm')\n",
        "\n",
        "# Mark true source time\n",
        "ax1.axvline(metadata['SourceTime'], color='green', linestyle='--', linewidth=2, \n",
        "            label=f\"True source (t={metadata['SourceTime']:.1f}s)\")\n",
        "\n",
        "# Remove duplicate labels\n",
        "handles, labels = ax1.get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "ax1.legend(by_label.values(), by_label.keys(), fontsize=11)\n",
        "\n",
        "# Plot 2: ARAD scores\n",
        "ax2.step(times, arad_scores, where='post', color='steelblue', linewidth=1.5, label='ARAD Score')\n",
        "ax2.axhline(detector.threshold, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Threshold ({detector.threshold:.4f})')\n",
        "ax2.set_xlabel('Time (s)', fontsize=12)\n",
        "ax2.set_ylabel('ARAD Score (CHI 2)', fontsize=12)\n",
        "ax2.set_title('ARAD Score Time Series', fontsize=13, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Highlight alarms\n",
        "for alarm in alarms:\n",
        "    ax2.axvspan(alarm['start_time'], alarm['end_time'], alpha=0.3, color='red')\n",
        "\n",
        "# Mark true source time\n",
        "ax2.axvline(metadata['SourceTime'], color='green', linestyle='--', linewidth=2)\n",
        "\n",
        "ax2.legend(fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Detection visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The ARAD detector successfully identified the source by learning background patterns and detecting when spectra deviate from the learned representation. The reconstruction error (CHI2) is higher for source-present spectra, enabling detection.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
